{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Environment Setup (simple_rl_environment Function):**<br>\n",
        "The environment consists of 2 states (State1, State2) and 2 actions (Action1, Action2).<br>\n",
        "A rewards dictionary is defined, specifying the reward for each state-action pair.<br>"
      ],
      "metadata": {
        "id": "3j9BnRKyFOnz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZJBM0ipRE60W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def simple_rl_environment():\n",
        "    \"\"\"\n",
        "    Creates a simple environment with 2 states and 2 actions.\n",
        "    \"\"\"\n",
        "    states = ['State1', 'State2']\n",
        "    actions = ['Action1', 'Action2']\n",
        "    rewards = {\n",
        "        'State1': {'Action1': 10, 'Action2': 0},\n",
        "        'State2': {'Action1': 0, 'Action2': 5}\n",
        "    }\n",
        "    return states, actions, rewards"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simple Agent Class (SimpleAgent):<br>**\n",
        "**Initialization (__init__):** The agent is initialized with the available states, actions, and the rewards structure. It starts in a random state.<br>\n",
        "**Choose Action (choose_action):** The agent selects an action randomly from the available actions.<br>\n",
        "**Take Action (take_action):** The agent receives a reward based on the current state and the chosen action. It then randomly transitions to a new state.<br>\n",
        "**Run (run):** The agent interacts with the environment for a specified number of episodes, prints each step, and accumulates the total reward.\n",
        "\n"
      ],
      "metadata": {
        "id": "SzHGrwldFead"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleAgent:\n",
        "    def __init__(self, states, actions, rewards):\n",
        "        \"\"\"\n",
        "        Initialize the agent with available states, actions, and the reward structure.\n",
        "        \"\"\"\n",
        "        self.states = states\n",
        "        self.actions = actions\n",
        "        self.rewards = rewards\n",
        "        self.current_state = np.random.choice(states)  # Start in a random state\n",
        "\n",
        "    def choose_action(self):\n",
        "        \"\"\"\n",
        "        Choose an action randomly.\n",
        "        \"\"\"\n",
        "        return np.random.choice(self.actions)\n",
        "\n",
        "    def take_action(self, action):\n",
        "        \"\"\"\n",
        "        Simulate taking an action in the environment and receive a reward.\n",
        "        \"\"\"\n",
        "        reward = self.rewards[self.current_state][action]  # Get the reward for the current state and action\n",
        "        # Transition to a new state (randomly for simplicity)\n",
        "        self.current_state = np.random.choice(self.states)\n",
        "        return reward\n",
        "\n",
        "    def run(self, episodes=10):\n",
        "        \"\"\"\n",
        "        Run the agent in the environment for a specified number of episodes.\n",
        "        \"\"\"\n",
        "        total_reward = 0\n",
        "        for episode in range(episodes):\n",
        "            action = self.choose_action()\n",
        "            reward = self.take_action(action)\n",
        "            total_reward += reward\n",
        "            print(f\"Episode {episode+1}: State={self.current_state}, Action={action}, Reward={reward}\")\n",
        "        print(f\"Total Reward after {episodes} episodes: {total_reward}\")\n",
        "\n",
        "# Initialize the environment\n",
        "states, actions, rewards = simple_rl_environment()\n",
        "\n",
        "# Create the agent\n",
        "agent = SimpleAgent(states, actions, rewards)\n",
        "\n",
        "# Run the agent\n",
        "agent.run(episodes=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjpL1pNXFD_L",
        "outputId": "2f2eab4c-c4c3-4205-c5be-557f2d7f52c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1: State=State2, Action=Action1, Reward=0\n",
            "Episode 2: State=State2, Action=Action2, Reward=5\n",
            "Episode 3: State=State1, Action=Action1, Reward=0\n",
            "Episode 4: State=State1, Action=Action2, Reward=0\n",
            "Episode 5: State=State2, Action=Action1, Reward=10\n",
            "Episode 6: State=State1, Action=Action1, Reward=0\n",
            "Episode 7: State=State1, Action=Action1, Reward=10\n",
            "Episode 8: State=State1, Action=Action2, Reward=0\n",
            "Episode 9: State=State1, Action=Action2, Reward=0\n",
            "Episode 10: State=State1, Action=Action1, Reward=10\n",
            "Total Reward after 10 episodes: 35\n"
          ]
        }
      ]
    }
  ]
}