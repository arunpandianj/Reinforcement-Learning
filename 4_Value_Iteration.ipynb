{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Value Iteration for a 4x4 Grid Navigation Problem"
      ],
      "metadata": {
        "id": "7jXt4yl8ek0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the agent's task is to reach the goal state (bottom-right corner of the grid) from any initial state on the grid. The agent receives a reward of +1 upon reaching the goal and -1 for each move to encourage reaching the goal quickly."
      ],
      "metadata": {
        "id": "4nZpBlVGeoL-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z0TmCS2fbiUW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the grid size\n",
        "grid_size = 4\n",
        "\n",
        "# Define the rewards for each state\n",
        "rewards = np.full((grid_size, grid_size), -1.0)  # Initialize with -1 for all moves\n",
        "rewards[grid_size - 1, grid_size - 1] = 0  # Goal state reward\n",
        "\n",
        "# Define value function (initialize to zero)\n",
        "values = np.zeros((grid_size, grid_size))\n",
        "\n",
        "# Define parameters\n",
        "gamma = 0.9  # Discount factor\n",
        "theta = 1e-4  # Convergence threshold\n",
        "actions = ['up', 'down', 'left', 'right']\n",
        "action_deltas = {'up': (-1, 0), 'down': (1, 0), 'left': (0, -1), 'right': (0, 1)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check if a state is terminal\n",
        "def is_terminal_state(x, y):\n",
        "    return (x == grid_size - 1 and y == grid_size - 1)\n",
        "\n",
        "# Function to get the next state given an action\n",
        "def get_next_state(x, y, action):\n",
        "    delta = action_deltas[action]\n",
        "    new_x, new_y = x + delta[0], y + delta[1]\n",
        "    if 0 <= new_x < grid_size and 0 <= new_y < grid_size:\n",
        "        return new_x, new_y\n",
        "    else:\n",
        "        return x, y  # No change if out of bounds\n",
        "\n",
        "# Value Iteration Algorithm\n",
        "iteration = 0\n",
        "while True:\n",
        "    delta = 0\n",
        "    new_values = np.copy(values)\n",
        "    for x in range(grid_size):\n",
        "        for y in range(grid_size):\n",
        "            if is_terminal_state(x, y):\n",
        "                continue\n",
        "            value_updates = []\n",
        "            for action in actions:\n",
        "                new_x, new_y = get_next_state(x, y, action)\n",
        "                reward = rewards[new_x, new_y]\n",
        "                value_updates.append(reward + gamma * values[new_x, new_y])\n",
        "            new_values[x, y] = max(value_updates)\n",
        "            delta = max(delta, abs(new_values[x, y] - values[x, y]))\n",
        "\n",
        "    values = new_values\n",
        "    iteration += 1\n",
        "\n",
        "    # Display the value function after each iteration\n",
        "    print(f\"\\nValue Function after iteration {iteration}:\")\n",
        "    print(values)\n",
        "\n",
        "    if delta < theta:\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28Z8gm5LgB_l",
        "outputId": "1189a587-dc24-44da-c8ca-b25c32d7c6ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Value Function after iteration 1:\n",
            "[[-1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1.]\n",
            " [-1. -1. -1.  0.]\n",
            " [-1. -1.  0.  0.]]\n",
            "\n",
            "Value Function after iteration 2:\n",
            "[[-1.9 -1.9 -1.9 -1.9]\n",
            " [-1.9 -1.9 -1.9 -1. ]\n",
            " [-1.9 -1.9 -1.   0. ]\n",
            " [-1.9 -1.   0.   0. ]]\n",
            "\n",
            "Value Function after iteration 3:\n",
            "[[-2.71 -2.71 -2.71 -1.9 ]\n",
            " [-2.71 -2.71 -1.9  -1.  ]\n",
            " [-2.71 -1.9  -1.    0.  ]\n",
            " [-1.9  -1.    0.    0.  ]]\n",
            "\n",
            "Value Function after iteration 4:\n",
            "[[-3.439 -3.439 -2.71  -1.9  ]\n",
            " [-3.439 -2.71  -1.9   -1.   ]\n",
            " [-2.71  -1.9   -1.     0.   ]\n",
            " [-1.9   -1.     0.     0.   ]]\n",
            "\n",
            "Value Function after iteration 5:\n",
            "[[-4.0951 -3.439  -2.71   -1.9   ]\n",
            " [-3.439  -2.71   -1.9    -1.    ]\n",
            " [-2.71   -1.9    -1.      0.    ]\n",
            " [-1.9    -1.      0.      0.    ]]\n",
            "\n",
            "Value Function after iteration 6:\n",
            "[[-4.0951 -3.439  -2.71   -1.9   ]\n",
            " [-3.439  -2.71   -1.9    -1.    ]\n",
            " [-2.71   -1.9    -1.      0.    ]\n",
            " [-1.9    -1.      0.      0.    ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the final value function\n",
        "print(\"\\nValue Function after Convergence:\")\n",
        "print(values)\n",
        "print(f\"Converged in {iteration} iterations.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im-7zei5fpUD",
        "outputId": "1dba74c5-573b-49b3-d849-76f51c62cce6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Value Function after Convergence:\n",
            "[[-4.0951 -3.439  -2.71   -1.9   ]\n",
            " [-3.439  -2.71   -1.9    -1.    ]\n",
            " [-2.71   -1.9    -1.      0.    ]\n",
            " [-1.9    -1.      0.      0.    ]]\n",
            "Converged in 6 iterations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the optimal policy\n",
        "policy = np.empty((grid_size, grid_size), dtype=str)\n",
        "for x in range(grid_size):\n",
        "    for y in range(grid_size):\n",
        "        if is_terminal_state(x, y):\n",
        "            policy[x, y] = 'Goal'\n",
        "        else:\n",
        "            best_action = None\n",
        "            best_value = float('-inf')\n",
        "            for action in actions:\n",
        "                new_x, new_y = get_next_state(x, y, action)\n",
        "                reward = rewards[new_x, new_y]\n",
        "                value = reward + gamma * values[new_x, new_y]\n",
        "                if value > best_value:\n",
        "                    best_value = value\n",
        "                    best_action = action\n",
        "            policy[x, y] = best_action\n",
        "\n",
        "# Display the optimal policy\n",
        "print(\"\\nOptimal Policy:\")\n",
        "for row in policy:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpkBiyRJgN-w",
        "outputId": "53102ea6-298b-451c-9cfd-78a867dee125"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimal Policy:\n",
            "['d' 'd' 'd' 'd']\n",
            "['d' 'd' 'd' 'd']\n",
            "['d' 'd' 'd' 'd']\n",
            "['r' 'r' 'r' 'G']\n"
          ]
        }
      ]
    }
  ]
}