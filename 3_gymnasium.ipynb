{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing a Custom Reinforcement Learning Environment using gymnasium"
      ],
      "metadata": {
        "id": "i4QERntzB8mN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages"
      ],
      "metadata": {
        "id": "EGeVKfFQCLf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium\n",
        "!pip install stable-baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRVLVM7s_n1y",
        "outputId": "8aadccd5-1772-4649-82a2-b58cbc4d0d1b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.4.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2024.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Custom Environment Using Gymnasium\n",
        "10 states (0, 1, 2, ..., 9).<br>\n",
        "2 possible actions (0 and 1).<br>\n",
        "The agent receives a reward when it reaches state 2 by taking the correct sequence of actions."
      ],
      "metadata": {
        "id": "kWdVHomGCQzq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nq7I_zh-_EYU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "class SimpleEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(SimpleEnv, self).__init__()\n",
        "\n",
        "        # Define action and observation spaces\n",
        "        self.observation_space = spaces.Discrete(10)  # Example: Discrete observation space with 10 possible states\n",
        "        self.action_space = spaces.Discrete(2)  # Example: Discrete action space with 2 possible actions\n",
        "\n",
        "        # Seed for reproducibility\n",
        "        self.seed()\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        # Set the random seed if provided\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        # Reset the environment to an initial state\n",
        "        initial_observation = 0\n",
        "\n",
        "        # Optionally, set other options for the environment reset\n",
        "\n",
        "        # Return the initial observation and additional info\n",
        "        return initial_observation, {}\n",
        "\n",
        "    def step(self, action):\n",
        "        # Implement your environment's step function\n",
        "        observation = np.random.choice(self.observation_space.n)  # Example: Randomly choose a new observation\n",
        "        reward = 1.0  # Example: Fixed reward\n",
        "        done = False  # Example: Fixed not done (change according to your terminal state logic)\n",
        "        info = {}\n",
        "        return observation, reward, done, False, info\n",
        "\n",
        "    def render(self, mode=\"human\"):\n",
        "        # Implement rendering logic if required\n",
        "        pass\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        # Set the seed for the environment's random number generator\n",
        "        np.random.seed(seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement an RL Agent Using Stable-Baselines3\n",
        "\n",
        "Now we will use the PPO (Proximal Policy Optimization) algorithm from Stable-Baselines3 to train an RL agent to interact with the SimpleEnv environment."
      ],
      "metadata": {
        "id": "lgaTb__PCuby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "# Create the custom environment\n",
        "env = SimpleEnv()\n",
        "\n",
        "# Instantiate the agent\n",
        "model = PPO('MlpPolicy', env, verbose=1)\n",
        "\n",
        "# Train the agent\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"ppo_simple_env\")\n",
        "\n",
        "# Test the trained agent\n",
        "obs, _ = env.reset()\n",
        "for _ in range(100):\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = env.step(action)\n",
        "    env.render()\n",
        "    if done:\n",
        "        print(\"Reached terminal state!\")\n",
        "        obs, _ = env.reset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFb2FjkP_L8D",
        "outputId": "b2ab4f83-7457-4339-d191-28f17c0d3473"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 583  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 3    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 8           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000980796 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.693      |\n",
            "|    explained_variance   | -0.0229     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 13.7        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.000752   |\n",
            "|    value_loss           | 159         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 481          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 12           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013202699 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.692       |\n",
            "|    explained_variance   | -0.0489      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 14.7         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.000804    |\n",
            "|    value_loss           | 101          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 479          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019385138 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.69        |\n",
            "|    explained_variance   | -0.000981    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 18.9         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00138     |\n",
            "|    value_loss           | 97           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006585312 |\n",
            "|    clip_fraction        | 0.00171     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.684      |\n",
            "|    explained_variance   | -0.00124    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 14.7        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0031     |\n",
            "|    value_loss           | 79.6        |\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgKv4H3ZEDeb",
        "outputId": "c9dc4c85-bf52-46ef-c9f8-aa6c91609541"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    }
  ]
}
